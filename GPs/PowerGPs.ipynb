{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZJ4LWPNW+f09bE5XqkmqY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sabelz/Master_Thesis_Alexander/blob/main/GPs/PowerGPs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Processes on the Power Plant dataset"
      ],
      "metadata": {
        "id": "lGZxtnuROxTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Master_Thesis_Alexander\n",
        "!git config --global user.email \"alexander.sabelstrom.1040@student.uu.se\"\n",
        "!git config --global user.name \"Sabelz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6C8woR2O5OV",
        "outputId": "99901792-7ad0-411c-ad1c-26361d9de3ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Master_Thesis_Alexander\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "ZheNcHosO81G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "!pip install gpytorch > \\dev\\null # Suppress prints\n",
        "import gpytorch\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%run \"datasets/power.ipynb\" # Run the Power notebook\n",
        "%run \"utils/models.ipynb\" # Run the models notebook\n",
        "%run \"utils/functions.ipynb\" # Run the functions notebook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCuFrto2O_aT",
        "outputId": "6a4217cc-c58e-45f7-e239-1f4da148d9b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Master_Thesis_Alexander\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9568 entries, 0 to 9567\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   AT      9568 non-null   float64\n",
            " 1   V       9568 non-null   float64\n",
            " 2   AP      9568 non-null   float64\n",
            " 3   RH      9568 non-null   float64\n",
            " 4   PE      9568 non-null   float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 373.9 KB\n",
            "None\n",
            "\n",
            "AT    False\n",
            "V     False\n",
            "AP    False\n",
            "RH    False\n",
            "PE    False\n",
            "dtype: bool\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Master_Thesis_Alexander\n",
            "----------------------------------------------------------\n",
            "ALL MODELS: \n",
            "KISS-GP For 1D-4D data:\n",
            "    Example:\n",
            "      likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
            "      mean = gpytorch.means.ConstantMean()\n",
            "      kernel = gpytorch.kernels.RBFKernel()\n",
            "      model = KISSGP(x_train, y_train, likelihood, mean, kernel)\n",
            "      model = model.to(device) # Move model to device\n",
            "\n",
            "KISS-GP For higher dimensional data:\n",
            "    Example:\n",
            "      likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
            "      mean = gpytorch.means.ConstantMean()\n",
            "      kernel = gpytorch.kernels.RBFKernel()\n",
            "      model = KISSGP_NDim(x_train, y_train, likelihood, mean, kernel)\n",
            "      model = model.to(device) # Move model to device\n",
            "\n",
            "Inducing Points GP:\n",
            "    Example:\n",
            "      likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
            "      mean = gpytorch.means.ConstantMean()\n",
            "      kernel = gpytorch.kernels.RBFKernel()\n",
            "      n_inducing_points = 500\n",
            "      inducing_points = x_train[torch.randperm(x_train.size(0))[:num_inducing_points]]\n",
            "      model = InducingGP(likelihood, mean, kernel, inducing_points)\n",
            "      model = model.to(device) # Move model to device.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Master_Thesis_Alexander\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare The Data"
      ],
      "metadata": {
        "id": "8m7WAYl7QE14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "powerPlant_data = df_PowerPlant # df_PowerPlant is defined in ../datasets/power.ipynb\n",
        "# The last column is output(net hourly electrical energy output (EP)  of the plant)\n",
        "x_power, y_power = powerPlant_data.iloc[:, :-1].to_numpy() , powerPlant_data.iloc[:, -1].to_numpy()\n",
        "\n",
        "\n",
        "x_train_power, x_test_power, y_train_power, y_test_power = train_test_split(x_power, y_power, test_size=0.2, random_state=666)\n",
        "# Transform into tensors\n",
        "x_train_power, x_test_power, y_train_power, y_test_power = (\n",
        "torch.from_numpy(x_train_power), torch.from_numpy(x_test_power),\n",
        "torch.from_numpy(y_train_power), torch.from_numpy(y_test_power))\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    x_train_power, y_train_power, x_test_power, y_test_power = (\n",
        "    x_train_power.cuda(), y_train_power.cuda(), x_test_power.cuda(), y_test_power.cuda())\n",
        "\n",
        "# Train data into batches\n",
        "train_dataset_power = TensorDataset(x_train_power, y_train_power)\n",
        "train_loader_power = DataLoader(train_dataset_power, batch_size=500, shuffle=True)\n",
        "\n",
        "# Test data into batches\n",
        "test_dataset_power = TensorDataset(x_test_power, y_test_power)\n",
        "test_loader_power = DataLoader(test_dataset_power, batch_size=500, shuffle=False)\n"
      ],
      "metadata": {
        "id": "JQKLanCDQGGW"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}