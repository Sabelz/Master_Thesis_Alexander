{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXMPBz+Dxg7w1cjT8dxRbN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sabelz/Master_Thesis_Alexander/blob/main/utils/PowerGPs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Processes on the Power Plant dataset"
      ],
      "metadata": {
        "id": "lGZxtnuROxTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Master_Thesis_Alexander\n",
        "!git config --global user.email \"alexander.sabelstrom.1040@student.uu.se\"\n",
        "!git config --global user.name \"Sabelz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6C8woR2O5OV",
        "outputId": "52195580-b141-4c9d-b986-6e8c0371a845"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Master_Thesis_Alexander\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "ZheNcHosO81G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "#!pip install gpytorch > \\dev\\null # Suppress prints\n",
        "import gpytorch\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%run \"datasets/power.ipynb\" # Run the Power notebook\n",
        "%run \"utils/models.ipynb\" # Run the models notebook\n",
        "%run \"utils/functions.ipynb\" # Run the functions notebook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCuFrto2O_aT",
        "outputId": "f5ce5315-15cb-435d-9052-6a432220a9ff"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Master_Thesis_Alexander\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9568 entries, 0 to 9567\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   AT      9568 non-null   float64\n",
            " 1   V       9568 non-null   float64\n",
            " 2   AP      9568 non-null   float64\n",
            " 3   RH      9568 non-null   float64\n",
            " 4   PE      9568 non-null   float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 373.9 KB\n",
            "None\n",
            "\n",
            "AT    False\n",
            "V     False\n",
            "AP    False\n",
            "RH    False\n",
            "PE    False\n",
            "dtype: bool\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Master_Thesis_Alexander\n",
            "----------------------------------------------------------\n",
            "ALL MODELS: \n",
            "KISS-GP For 1D-4D data:\n",
            "    Example:\n",
            "      likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
            "      mean = gpytorch.means.ConstantMean()\n",
            "      kernel = gpytorch.kernels.RBFKernel()\n",
            "      model = KISSGP(x_train, y_train, likelihood, mean, kernel)\n",
            "      model = model.to(device) # Move model to device\n",
            "\n",
            "KISS-GP For higher dimensional data:\n",
            "    Example:\n",
            "      likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
            "      mean = gpytorch.means.ConstantMean()\n",
            "      kernel = gpytorch.kernels.RBFKernel()\n",
            "      model = KISSGP_NDim(x_train, y_train, likelihood, mean, kernel)\n",
            "      model = model.to(device) # Move model to device\n",
            "\n",
            "Inducing Points GP:\n",
            "    Example:\n",
            "      likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
            "      mean = gpytorch.means.ConstantMean()\n",
            "      kernel = gpytorch.kernels.RBFKernel()\n",
            "      n_inducing_points = 500\n",
            "      inducing_points = x_train[torch.randperm(x_train.size(0))[:num_inducing_points]]\n",
            "      model = InducingGP(likelihood, mean, kernel, inducing_points)\n",
            "      model = model.to(device) # Move model to device.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Master_Thesis_Alexander\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare The Data"
      ],
      "metadata": {
        "id": "8m7WAYl7QE14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "powerPlant_data = df_PowerPlant # df_PowerPlant is defined in ../datasets/power.ipynb\n",
        "# The last column is output(net hourly electrical energy output (EP)  of the plant)\n",
        "x_power, y_power = powerPlant_data.iloc[:, :-1].to_numpy() , powerPlant_data.iloc[:, -1].to_numpy()\n",
        "\n",
        "\n",
        "x_train_power, x_test_power, y_train_power, y_test_power = train_test_split(x_power, y_power, test_size=0.2, random_state=666)\n",
        "# Transform into tensors\n",
        "x_train_power, x_test_power, y_train_power, y_test_power = (\n",
        "torch.from_numpy(x_train_power).float(), torch.from_numpy(x_test_power).float(),\n",
        "torch.from_numpy(y_train_power).float(), torch.from_numpy(y_test_power).float())\n",
        "\n",
        "# Standardized data\n",
        "scaler = StandardScaler()\n",
        "x_train_power_standardized = torch.from_numpy(scaler.fit_transform(x_train_power)).float()\n",
        "# Use the same scaler that was used on training data\n",
        "x_test_power_standardized = torch.from_numpy(scaler.transform(x_test_power)).float()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    x_train_power, y_train_power, x_test_power, y_test_power, x_train_power_standardized, x_test_power_standardized = (\n",
        "    x_train_power.cuda(), y_train_power.cuda(), x_test_power.cuda(), y_test_power.cuda(),\n",
        "    x_train_power_standardized.cuda(), x_test_power_standardized.cuda())\n",
        "\n",
        "# Train data into batches\n",
        "train_dataset_power = TensorDataset(x_train_power, y_train_power)\n",
        "train_loader_power = DataLoader(train_dataset_power, batch_size=500, shuffle=True)\n",
        "\n",
        "# Test data into batches\n",
        "test_dataset_power = TensorDataset(x_test_power, y_test_power)\n",
        "test_loader_power = DataLoader(test_dataset_power, batch_size=500, shuffle=False)"
      ],
      "metadata": {
        "id": "JQKLanCDQGGW"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the KISS-GP Model for 1D-4D data"
      ],
      "metadata": {
        "id": "o414crpg-yT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KISSGP_likelihood_power = gpytorch.likelihoods.GaussianLikelihood() # Likelihood\n",
        "KISSGP_mean_power = gpytorch.means.ConstantMean() # Mean\n",
        "KISSGP_kernel_power = gpytorch.kernels.RBFKernel() # Kernel\n",
        "KISSGP_model_power = KISSGP_NDim(x_train_power, y_train_power, KISSGP_likelihood_power, KISSGP_mean_power, KISSGP_kernel_power) # KISSGP defined in utils/Models.ipynb\n",
        "# One with standardized features\n",
        "KISSGP_likelihood_power_standardized = gpytorch.likelihoods.GaussianLikelihood() # Likelihood\n",
        "KISSGP_mean_power_standardized = gpytorch.means.ConstantMean() # Mean\n",
        "KISSGP_kernel_power_standardized = gpytorch.kernels.RBFKernel() # Kernel\n",
        "KISSGP_model_power_standardized = KISSGP_NDim(x_train_power_standardized, y_train_power,\n",
        "                                              KISSGP_likelihood_power_standardized, KISSGP_mean_power_standardized, KISSGP_kernel_power_standardized) # KISSGP defined in utils/Models.ipynb"
      ],
      "metadata": {
        "id": "-6cmLoDC-61z"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Evaluate the KISS-GP Model"
      ],
      "metadata": {
        "id": "wk1J59hX_a7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KISSGP_power_time = train(KISSGP_model_power, KISSGP_likelihood_power,\n",
        "                          x_train_power, y_train_power, training_iter= 40) # train is defined in utils/functions.ipynb\n",
        "# Standardized version\n",
        "KISSGP_power_time_standardized = train(KISSGP_model_power_standardized, KISSGP_likelihood_power_standardized,\n",
        "                                       x_train_power_standardized, y_train_power, training_iter= 40) # train is defined in utils/functions.ipynb"
      ],
      "metadata": {
        "id": "e4xnVJHZ_fak"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
        "  predictions_KISSGP_power = predict(KISSGP_model_power, KISSGP_likelihood_power,\n",
        "                                     x_test_power) # predict is defined in utils/functions.ipynb\n",
        "\n",
        "  RMSE_KISSGP_power, NLPD_KISSGP_power = error_metrics(x_test_power, y_test_power,\n",
        "                                    predictions_KISSGP_power.mean,\n",
        "                                    model = KISSGP_model_power,\n",
        "                                    likelihood = KISSGP_likelihood_power)# error_metrics defined in utils/functions.ipynb\n",
        "\n",
        "\n",
        "  # Standardized version\n",
        "  predictions_KISSGP_power_standardized = predict(KISSGP_model_power_standardized, KISSGP_likelihood_power_standardized,\n",
        "                                                  x_test_power_standardized) # predict is defined in utils/functions.ipynb\n",
        "\n",
        "  RMSE_KISSGP_power_standardized, NLPD_KISSGP_power_standardized = error_metrics(x_test_power_standardized, y_test_power,\n",
        "                                    predictions_KISSGP_power_standardized.mean,\n",
        "                                    model = KISSGP_model_power_standardized,\n",
        "                                    likelihood = KISSGP_likelihood_power_standardized)# error_metrics defined in utils/functions.ipynb\n",
        "\n",
        "\n",
        "  print(\"RMSE KISS-GP: \",RMSE_KISSGP_power)\n",
        "  print(\"NLPD KISS-GP: \",NLPD_KISSGP_power)\n",
        "  print(\"Time KISS-GP: \", KISSGP_power_time)\n",
        "\n",
        "  print(\"RMSE KISS-GP Standardized: \",RMSE_KISSGP_power_standardized)\n",
        "  print(\"NLPD KISS-GP Standardized: \",NLPD_KISSGP_power_standardized)\n",
        "  print(\"Time KISS-GP Standardized: \", KISSGP_power_time_standardized)"
      ],
      "metadata": {
        "id": "WPI-cYjpBPdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c525fd-6398-4d9a-a596-01fd90b3a7e8"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 464.9206848144531 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE KISS-GP:  4.3208427\n",
            "NLPD KISS-GP:  tensor(8.0668, device='cuda:0')\n",
            "Time KISS-GP:  23.90242838859558\n",
            "RMSE KISS-GP Standardized:  4.9411435\n",
            "NLPD KISS-GP Standardized:  tensor(5.4955, device='cuda:0')\n",
            "Time KISS-GP Standardized:  11.596442222595215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inducing Points Model"
      ],
      "metadata": {
        "id": "wtEd0t-NBmgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inducing_likelihood_power = gpytorch.likelihoods.GaussianLikelihood()\n",
        "inducing_mean_power = gpytorch.means.ConstantMean()\n",
        "inducing_kernel_power = gpytorch.kernels.RBFKernel()\n",
        "n_inducing_points = 150\n",
        "# Generate a tensor of random indices\n",
        "indices = torch.randperm(x_train_power.size(0))\n",
        "# Select N random rows\n",
        "inducing_points = x_train_power[indices][:n_inducing_points]\n",
        "inducing_model_power = InducingGP(inducing_likelihood_power, inducing_mean_power, inducing_kernel_power, inducing_points) # InducingGP defined in utils/models.ipynb\n",
        "inducing_model_power = inducing_model_power.to(device) # Move model to device, defined in utils/models.ipynb"
      ],
      "metadata": {
        "id": "B2Ppw-GGBvYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Evaluate Inducing Points Model"
      ],
      "metadata": {
        "id": "YlE9whGIDngd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_loader_power\n",
        "inducing_power_time = train_ELBO(inducing_model_power, inducing_likelihood_power, x_train_power, y_train_power, training_iter= 1000, train_loader=train_loader_power) # train is defined in utils/functions.ipynb"
      ],
      "metadata": {
        "id": "NcH2FD4fDpck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
        "  # predict is defined in utils/functions.ipynb\n",
        "  predictions_inducing_power = predict(inducing_model_power, inducing_likelihood_power, x_test_power)\n",
        "\n",
        "  # Root Mean Square Error(RMSE)\n",
        "  # NumPy can only handle CPU tensors\n",
        "  y_test_power_cpu = y_test_power.cpu()\n",
        "  predictions_inducing_power_cpu = predictions_inducing_power.mean.cpu()\n",
        "  RMSE_inducing_power = mean_squared_error(y_test_power_cpu, predictions_inducing_power_cpu, squared=False)\n",
        "  print(\"RMSE Inducing Model: \",RMSE_inducing_power)\n",
        "  print(\"Time Inducing Model: \", lnducing_power_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn4BU7bCE643",
        "outputId": "3eb54d77-2f91-4843-d77f-0019a25b21c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE Inducing Model:  4.354558303746978\n"
          ]
        }
      ]
    }
  ]
}